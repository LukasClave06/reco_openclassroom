{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe34e3cb",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aaac5c",
   "metadata": {},
   "source": [
    "Fusion des dataframmes clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60a2d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:04<00:00, 90.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichiers fusionnés : (2988181, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Répertoire contenant les fichiers\n",
    "click_dir = \"../data/clicks/\"\n",
    "\n",
    "# Fusionner tous les fichiers CSV\n",
    "all_clicks = []\n",
    "\n",
    "for file in tqdm(os.listdir(click_dir)):\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(click_dir, file))\n",
    "        all_clicks.append(df)\n",
    "\n",
    "df_clicks = pd.concat(all_clicks, ignore_index=True)\n",
    "print(\"✅ Fichiers fusionnés :\", df_clicks.shape)\n",
    "df_clicks.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb4de9",
   "metadata": {},
   "source": [
    "Aperçu premières lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f720d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>157541</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>68866</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>235840</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>96663</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>1506825435000</td>\n",
       "      <td>2</td>\n",
       "      <td>119592</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id        session_id  session_start session_size click_article_id  \\\n",
       "0       0  1506825423271737  1506825423000            2           157541   \n",
       "1       0  1506825423271737  1506825423000            2            68866   \n",
       "2       1  1506825426267738  1506825426000            2           235840   \n",
       "3       1  1506825426267738  1506825426000            2            96663   \n",
       "4       2  1506825435299739  1506825435000            2           119592   \n",
       "\n",
       "  click_timestamp click_environment click_deviceGroup click_os click_country  \\\n",
       "0   1506826828020                 4                 3       20             1   \n",
       "1   1506826858020                 4                 3       20             1   \n",
       "2   1506827017951                 4                 1       17             1   \n",
       "3   1506827047951                 4                 1       17             1   \n",
       "4   1506827090575                 4                 1       17             1   \n",
       "\n",
       "  click_region click_referrer_type  \n",
       "0           20                   2  \n",
       "1           20                   2  \n",
       "2           16                   2  \n",
       "3           16                   2  \n",
       "4           24                   2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf7281",
   "metadata": {},
   "source": [
    "Vérification des types et valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c7417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2988181 entries, 0 to 2988180\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Dtype \n",
      "---  ------               ----- \n",
      " 0   user_id              object\n",
      " 1   session_id           object\n",
      " 2   session_start        object\n",
      " 3   session_size         object\n",
      " 4   click_article_id     object\n",
      " 5   click_timestamp      object\n",
      " 6   click_environment    object\n",
      " 7   click_deviceGroup    object\n",
      " 8   click_os             object\n",
      " 9   click_country        object\n",
      " 10  click_region         object\n",
      " 11  click_referrer_type  object\n",
      "dtypes: object(12)\n",
      "memory usage: 273.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clicks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432dda6",
   "metadata": {},
   "source": [
    "Toutes tes colonnes sont en object, y compris :\n",
    "\n",
    "user_id\n",
    "\n",
    "click_article_id\n",
    "\n",
    "click_timestamp\n",
    "\n",
    "session_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993b92b",
   "metadata": {},
   "source": [
    "### Etape suivante : convertir les types\n",
    "\n",
    "On convertit pas directement click_timestamp en datetime, on préfère crée une nouvelle colonne click_datetime pour avoir les deux infos a portée de main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92499160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                0\n",
      "session_id             0\n",
      "session_start          0\n",
      "session_size           0\n",
      "click_article_id       0\n",
      "click_timestamp        0\n",
      "click_environment      0\n",
      "click_deviceGroup      0\n",
      "click_os               0\n",
      "click_country          0\n",
      "click_region           0\n",
      "click_referrer_type    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2988181 entries, 0 to 2988180\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   user_id              int64         \n",
      " 1   session_id           int64         \n",
      " 2   session_start        int64         \n",
      " 3   session_size         int64         \n",
      " 4   click_article_id     int64         \n",
      " 5   click_timestamp      int64         \n",
      " 6   click_environment    int64         \n",
      " 7   click_deviceGroup    int64         \n",
      " 8   click_os             int64         \n",
      " 9   click_country        int64         \n",
      " 10  click_region         int64         \n",
      " 11  click_referrer_type  int64         \n",
      " 12  click_datetime       datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(12)\n",
      "memory usage: 296.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Conversion des colonnes en types numériques et datetime\n",
    "cols_int = [\n",
    "    \"user_id\",\n",
    "    \"session_id\",\n",
    "    \"session_start\",\n",
    "    \"session_size\",\n",
    "    \"click_article_id\",\n",
    "    \"click_timestamp\",\n",
    "    \"click_environment\",\n",
    "    \"click_deviceGroup\",\n",
    "    \"click_os\",\n",
    "    \"click_country\",\n",
    "    \"click_region\",\n",
    "    \"click_referrer_type\"\n",
    "]\n",
    "\n",
    "for col in cols_int:\n",
    "    df_clicks[col] = pd.to_numeric(df_clicks[col], errors=\"coerce\")\n",
    "\n",
    "# Vérifier qu'il n'y a pas de valeurs manquantes après conversion\n",
    "print(df_clicks.isnull().sum())\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df_clicks[\"click_datetime\"] = pd.to_datetime(df_clicks[\"click_timestamp\"], unit=\"ms\")\n",
    "\n",
    "# Vérifier la structure après conversion\n",
    "df_clicks.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4202bba",
   "metadata": {},
   "source": [
    "Création de la table d'intéraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b5b992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>event_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349865</th>\n",
       "      <td>16280</td>\n",
       "      <td>68851</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349924</th>\n",
       "      <td>16280</td>\n",
       "      <td>237071</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349969</th>\n",
       "      <td>16280</td>\n",
       "      <td>363925</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349859</th>\n",
       "      <td>16280</td>\n",
       "      <td>43032</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349853</th>\n",
       "      <td>16280</td>\n",
       "      <td>38823</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61867</th>\n",
       "      <td>2520</td>\n",
       "      <td>237807</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643904</th>\n",
       "      <td>33937</td>\n",
       "      <td>225378</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643895</th>\n",
       "      <td>33937</td>\n",
       "      <td>96173</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373759</th>\n",
       "      <td>188046</td>\n",
       "      <td>69463</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224039</th>\n",
       "      <td>10188</td>\n",
       "      <td>73431</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  event_strength\n",
       "349865     16280             68851              33\n",
       "349924     16280            237071              33\n",
       "349969     16280            363925              33\n",
       "349859     16280             43032              31\n",
       "349853     16280             38823              30\n",
       "61867       2520            237807              17\n",
       "643904     33937            225378              16\n",
       "643895     33937             96173              16\n",
       "2373759   188046             69463              13\n",
       "224039     10188             73431              13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1️⃣ Chaque clic compte pour 1 point d'intérêt\n",
    "df_clicks[\"event_strength\"] = 1\n",
    "\n",
    "# 2️⃣ Agréger le nombre de clics par utilisateur et article\n",
    "df_user_item = df_clicks.groupby(\n",
    "    [\"user_id\", \"click_article_id\"]\n",
    ")[\"event_strength\"].sum().reset_index()\n",
    "\n",
    "# 3️⃣ Trier pour un aperçu lisible\n",
    "df_user_item = df_user_item.sort_values(by=\"event_strength\", ascending=False)\n",
    "\n",
    "# 4️⃣ Afficher les 10 plus grosses interactions\n",
    "df_user_item.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0c08a",
   "metadata": {},
   "source": [
    "Split train/test temporel.\n",
    "\n",
    "Le split temporel permet de simuler un scénario réel où l’on prédit les comportements futurs des utilisateurs à partir de leur historique passé. Cela évite la fuite de données et garantit que le modèle n’apprend pas sur des interactions postérieures à la période d’entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f9017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : de 2017-10-01 03:00:00.026000 à 2017-10-12 21:20:12.384000\n",
      "Test  : de 2017-10-12 21:20:12.579000 à 2017-11-13 20:04:14.886000\n",
      "Train size : 2390544\n",
      "Test size : 597637\n"
     ]
    }
   ],
   "source": [
    "# On repart de df_clicks (lignes brutes avec les timestamps)\n",
    "# Tri chronologique\n",
    "df_clicks_sorted = df_clicks.sort_values(by=\"click_timestamp\")\n",
    "\n",
    "# Calcul de l'index de coupure 80/20\n",
    "split_index = int(0.8 * len(df_clicks_sorted))\n",
    "\n",
    "# Split temporel\n",
    "df_train = df_clicks_sorted.iloc[:split_index]\n",
    "df_test = df_clicks_sorted.iloc[split_index:]\n",
    "\n",
    "# Afficher les bornes temporelles\n",
    "print(\"Train : de\", df_train['click_datetime'].min(), \"à\", df_train['click_datetime'].max())\n",
    "print(\"Test  : de\", df_test['click_datetime'].min(), \"à\", df_test['click_datetime'].max())\n",
    "\n",
    "# Vérifier les tailles\n",
    "print(\"Train size :\", len(df_train))\n",
    "print(\"Test size :\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd1249",
   "metadata": {},
   "source": [
    "### Préparer les données pour la librairie Surprise.\n",
    "\n",
    "On va créer un dataset compatible avec Surprise :\n",
    "\n",
    "Format = user_id, item_id, rating\n",
    "\n",
    "Ici rating = event_strength\n",
    "\n",
    "Note :\n",
    "Surprise n’accepte que des ratings positifs (pas de 0), mais ici tout est ≥1, donc pas de souci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec316f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Surprise prêt.\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Pour Surprise, on n'a besoin que de ces 3 colonnes\n",
    "train_data = df_train[[\"user_id\", \"click_article_id\"]].copy()\n",
    "train_data[\"event_strength\"] = 1  # Chaque clic vaut 1\n",
    "\n",
    "# Comme on a potentiellement plusieurs clics par user/article, on les agrège\n",
    "train_data_agg = train_data.groupby(\n",
    "    [\"user_id\", \"click_article_id\"]\n",
    ").sum().reset_index()\n",
    "\n",
    "# Idem pour le test\n",
    "test_data = df_test[[\"user_id\", \"click_article_id\"]].copy()\n",
    "test_data[\"event_strength\"] = 1\n",
    "\n",
    "test_data_agg = test_data.groupby(\n",
    "    [\"user_id\", \"click_article_id\"]\n",
    ").sum().reset_index()\n",
    "\n",
    "# Définir le Reader : Surprise attend un rating_min et rating_max\n",
    "reader = Reader(rating_scale=(1, train_data_agg[\"event_strength\"].max()))\n",
    "\n",
    "# Convertir en dataset Surprise\n",
    "train_dataset = Dataset.load_from_df(\n",
    "    train_data_agg[[\"user_id\", \"click_article_id\", \"event_strength\"]],\n",
    "    reader\n",
    ")\n",
    "\n",
    "# Pour l'évaluation, on créera un testset séparé\n",
    "print(\"✅ Dataset Surprise prêt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bcd383",
   "metadata": {},
   "source": [
    "Entrainer un modèle SVD :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23236650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 0.1366\n",
      "✅ Modèle SVD entraîné, RMSE = 0.1366\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# On divise le dataset Surprise en train/test (ici 80/20)\n",
    "trainset, valset = train_test_split(train_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser le modèle SVD\n",
    "svd_model = SVD(n_factors=50, n_epochs=20, verbose=True)\n",
    "\n",
    "# Entraîner\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Prédire sur le set de validation\n",
    "predictions = svd_model.test(valset)\n",
    "\n",
    "# Évaluer la RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "\n",
    "print(f\"✅ Modèle SVD entraîné, RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd62d9c",
   "metadata": {},
   "source": [
    "### Générer le top 5 des recommandations \n",
    "\n",
    "Pour faire ça :\n",
    "\n",
    "On prend un utilisateur.\n",
    "\n",
    "On parcourt tous les articles qu’il n’a pas encore cliqués.\n",
    "\n",
    "On prédit le “rating” de ces articles.\n",
    "\n",
    "On trie par score décroissant.\n",
    "\n",
    "On garde les 5 premiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b10d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Top 5 recommandations pour l'utilisateur 0\n",
      "- Article 68851 (score estimé: 2.6776)\n",
      "- Article 73431 (score estimé: 1.9246)\n",
      "- Article 225378 (score estimé: 1.8289)\n",
      "- Article 43032 (score estimé: 1.7261)\n",
      "- Article 38823 (score estimé: 1.7181)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_n_recommendations(model, user_id, all_item_ids, known_items, n=5):\n",
    "    \"\"\"\n",
    "    model: modèle SVD entraîné\n",
    "    user_id: identifiant utilisateur\n",
    "    all_item_ids: liste de tous les articles\n",
    "    known_items: liste des articles déjà vus par l'utilisateur\n",
    "    n: nombre de recommandations\n",
    "    \"\"\"\n",
    "    # Articles que l'utilisateur n'a pas encore cliqués\n",
    "    items_to_predict = [iid for iid in all_item_ids if iid not in known_items]\n",
    "    \n",
    "    # Prédire les notes\n",
    "    predictions = [model.predict(user_id, iid) for iid in items_to_predict]\n",
    "    \n",
    "    # Trier par rating décroissant\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Retourner les n meilleurs\n",
    "    top_n = predictions[:n]\n",
    "    return [(pred.iid, pred.est) for pred in top_n]\n",
    "\n",
    "# Exemple: générer les recommandations pour un user_id au hasard\n",
    "all_articles = df_clicks[\"click_article_id\"].unique()\n",
    "some_user = train_data_agg[\"user_id\"].iloc[0]\n",
    "\n",
    "# Récupérer les articles déjà cliqués par cet utilisateur\n",
    "user_clicked_articles = train_data_agg[train_data_agg[\"user_id\"] == some_user][\"click_article_id\"].tolist()\n",
    "\n",
    "# Obtenir les recommandations\n",
    "reco = get_top_n_recommendations(svd_model, some_user, all_articles, user_clicked_articles, n=5)\n",
    "\n",
    "print(\"✅ Top 5 recommandations pour l'utilisateur\", some_user)\n",
    "for art_id, score in reco:\n",
    "    print(f\"- Article {art_id} (score estimé: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fe1a8",
   "metadata": {},
   "source": [
    "Test avec diffénrents utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21839d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Recommandations pour l'utilisateur 178107\n",
      "- Article 68851 (score estimé: 2.9396)\n",
      "- Article 43032 (score estimé: 2.0164)\n",
      "- Article 38823 (score estimé: 1.9999)\n",
      "- Article 73431 (score estimé: 1.8042)\n",
      "- Article 146230 (score estimé: 1.7560)\n",
      "\n",
      "✅ Recommandations pour l'utilisateur 193327\n",
      "- Article 68851 (score estimé: 2.1882)\n",
      "- Article 73431 (score estimé: 1.9914)\n",
      "- Article 146230 (score estimé: 1.7919)\n",
      "- Article 105941 (score estimé: 1.6686)\n",
      "- Article 225378 (score estimé: 1.6564)\n",
      "\n",
      "✅ Recommandations pour l'utilisateur 195824\n",
      "- Article 68851 (score estimé: 2.8331)\n",
      "- Article 43032 (score estimé: 2.1154)\n",
      "- Article 225378 (score estimé: 2.0914)\n",
      "- Article 38823 (score estimé: 2.0493)\n",
      "- Article 73431 (score estimé: 1.9106)\n",
      "\n",
      "✅ Recommandations pour l'utilisateur 97816\n",
      "- Article 68851 (score estimé: 2.7213)\n",
      "- Article 38823 (score estimé: 1.9084)\n",
      "- Article 146230 (score estimé: 1.8717)\n",
      "- Article 73431 (score estimé: 1.7886)\n",
      "- Article 43032 (score estimé: 1.7123)\n",
      "\n",
      "✅ Recommandations pour l'utilisateur 72040\n",
      "- Article 68851 (score estimé: 2.3320)\n",
      "- Article 73431 (score estimé: 1.8613)\n",
      "- Article 62197 (score estimé: 1.6381)\n",
      "- Article 185608 (score estimé: 1.6266)\n",
      "- Article 225378 (score estimé: 1.6092)\n"
     ]
    }
   ],
   "source": [
    "# Exemple : tester plusieurs utilisateurs aléatoires\n",
    "import numpy as np\n",
    "\n",
    "user_ids_sample = np.random.choice(train_data_agg[\"user_id\"].unique(), size=5, replace=False)\n",
    "\n",
    "for user_id in user_ids_sample:\n",
    "    # Articles déjà cliqués par l'utilisateur\n",
    "    clicked = train_data_agg[train_data_agg[\"user_id\"] == user_id][\"click_article_id\"].tolist()\n",
    "    \n",
    "    # Recommandations\n",
    "    reco = get_top_n_recommendations(svd_model, user_id, all_articles, clicked, n=5)\n",
    "    \n",
    "    print(f\"\\n✅ Recommandations pour l'utilisateur {user_id}\")\n",
    "    for art_id, score in reco:\n",
    "        print(f\"- Article {art_id} (score estimé: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e74f4",
   "metadata": {},
   "source": [
    "Pourquoi l’article 68851 est recommandé à presque tous les utilisateurs ?\n",
    "Plusieurs raisons peuvent expliquer ce comportement du modèle SVD :\n",
    "\n",
    "1. Effet de popularité\n",
    "L’article 68851 est probablement l’un des plus cliqués de tout le dataset.\n",
    "Le modèle SVD apprend des tendances globales et peut considérer cet article comme un \"valeur sûre\" à recommander par défaut.\n",
    "\n",
    "2. Biais des données\n",
    "Si de nombreux utilisateurs interagissent avec les mêmes articles ou si le dataset est déséquilibré, certains articles ressortent fortement, surtout s’ils apparaissent souvent dans la période d'entraînement.\n",
    "\n",
    "3. Fonctionnement du SVD\n",
    "Le modèle SVD décompose les interactions utilisateur/article en facteurs latents.\n",
    "En l’absence de signaux très personnalisés pour un utilisateur, le modèle peut privilégier les articles avec un biais global élevé, donc perçus comme \"bons en général\".\n",
    "\n",
    "4. Pas nécessairement une erreur\n",
    "Ce comportement peut être acceptable si 68851 est effectivement très populaire.\n",
    "Cependant, cela peut nuire à la diversité des recommandations, ce qui est un aspect à surveiller selon les objectifs du projet.\n",
    "\n",
    "Conclusion : Ce n’est pas forcément un bug, mais un effet typique des modèles collaboratifs sur des données biaisées ou déséquilibrées. Si besoin, on peut combiner avec du content-based ou appliquer un post-traitement pour plus de diversité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97599622",
   "metadata": {},
   "source": [
    "## Content-base Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996245b",
   "metadata": {},
   "source": [
    "Étape 1 – Imports et chargement des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee7b7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3878ee9",
   "metadata": {},
   "source": [
    "Étape 2 – Charger la matrice des embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bc3353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings chargés.\n",
      "Shape de la matrice embeddings : (364047, 250)\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers le fichier embeddings\n",
    "embeddings_path = \"../data/articles_embeddings.pickle\"\n",
    "\n",
    "# Chargement\n",
    "with open(embeddings_path, \"rb\") as f:\n",
    "    articles_embeddings = pickle.load(f)\n",
    "\n",
    "print(\"✅ Embeddings chargés.\")\n",
    "print(\"Shape de la matrice embeddings :\", articles_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d850d14",
   "metadata": {},
   "source": [
    "Étape 3 – Charger les métadonnées des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11521c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadata chargées.\n",
      "Shape : (364047, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250\n",
       "3           3            1  1408468313000             0          230\n",
       "4           4            1  1407071171000             0          162"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les métadonnées\n",
    "df_articles = pd.read_csv(\"../data/articles_metadata.csv\")\n",
    "\n",
    "print(\"✅ Metadata chargées.\")\n",
    "print(\"Shape :\", df_articles.shape)\n",
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30847767",
   "metadata": {},
   "source": [
    "Étape 4 – Créer un DataFrame article_id + embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea95cf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame embeddings créé.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.16118301, -0.95723313, -0.13794445, 0.0508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.52321565, -0.974058, 0.73860806, 0.1552344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.61961854, -0.9729604, -0.20736018, -0.1288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.7408434, -0.97574896, 0.39169782, 0.641737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.2790515, -0.97231525, 0.68537366, 0.113056...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                          embedding\n",
       "0           0  [-0.16118301, -0.95723313, -0.13794445, 0.0508...\n",
       "1           1  [-0.52321565, -0.974058, 0.73860806, 0.1552344...\n",
       "2           2  [-0.61961854, -0.9729604, -0.20736018, -0.1288...\n",
       "3           3  [-0.7408434, -0.97574896, 0.39169782, 0.641737...\n",
       "4           4  [-0.2790515, -0.97231525, 0.68537366, 0.113056..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création d'une DataFrame avec article_id et embeddings\n",
    "df_embeddings = pd.DataFrame({\n",
    "    \"article_id\": df_articles[\"article_id\"].astype(int),\n",
    "    \"embedding\": list(articles_embeddings)\n",
    "})\n",
    "\n",
    "print(\"✅ DataFrame embeddings créé.\")\n",
    "df_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8854a7",
   "metadata": {},
   "source": [
    "### Étape 5 – Fonction de recommandation Content-Based\n",
    "\n",
    "Voici la fonction complète qui :\n",
    "\n",
    "Récupère les articles lus par un utilisateur\n",
    "\n",
    "Calcule la moyenne des embeddings de ces articles\n",
    "\n",
    "Calcule les similarités cosine avec tous les autres articles\n",
    "\n",
    "Retourne le top N articles non lus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7289b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_content_based_recommendations(user_id, df_user_clicks, df_embeddings, top_n=5):\n",
    "    \"\"\"\n",
    "    user_id : identifiant utilisateur\n",
    "    df_user_clicks : DataFrame avec colonnes ['user_id', 'click_article_id']\n",
    "    df_embeddings : DataFrame avec colonnes ['article_id', 'embedding']\n",
    "    \"\"\"\n",
    "    # Articles déjà cliqués par l'utilisateur\n",
    "    clicked_articles = df_user_clicks[df_user_clicks[\"user_id\"] == user_id][\"click_article_id\"].unique()\n",
    "    \n",
    "    if len(clicked_articles) == 0:\n",
    "        print(\"⚠️ Cet utilisateur n'a cliqué sur aucun article.\")\n",
    "        return []\n",
    "    \n",
    "    # Embeddings des articles cliqués\n",
    "    embeddings_clicked = df_embeddings[df_embeddings[\"article_id\"].isin(clicked_articles)][\"embedding\"].tolist()\n",
    "    \n",
    "    # Moyenne des embeddings\n",
    "    user_profile = np.mean(embeddings_clicked, axis=0).reshape(1, -1)\n",
    "    \n",
    "    # Embeddings de tous les articles\n",
    "    all_embeddings = np.stack(df_embeddings[\"embedding\"].values)\n",
    "    \n",
    "    # Similarité cosine\n",
    "    similarities = cosine_similarity(user_profile, all_embeddings).flatten()\n",
    "    \n",
    "    # Créer un DataFrame avec scores\n",
    "    df_scores = pd.DataFrame({\n",
    "        \"article_id\": df_embeddings[\"article_id\"],\n",
    "        \"similarity\": similarities\n",
    "    })\n",
    "    \n",
    "    # Retirer les articles déjà vus\n",
    "    df_scores = df_scores[~df_scores[\"article_id\"].isin(clicked_articles)]\n",
    "    \n",
    "    # Top N\n",
    "    top_recommendations = df_scores.sort_values(by=\"similarity\", ascending=False).head(top_n)\n",
    "    \n",
    "    return top_recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bceda2c",
   "metadata": {},
   "source": [
    "On récupère l'historique des clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd2ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_clicks = df_clicks[[\"user_id\", \"click_article_id\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3104ad5",
   "metadata": {},
   "source": [
    "Étape : Générer un exemple de recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bac9020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Recommandations Content-Based pour l'utilisateur 0\n",
      "        article_id  similarity\n",
      "162235      162235    0.874799\n",
      "160966      160966    0.848911\n",
      "162230      162230    0.841757\n",
      "155943      155943    0.841703\n",
      "160079      160079    0.841227\n"
     ]
    }
   ],
   "source": [
    "# Choisir un user_id présent dans tes clics train\n",
    "some_user_id = df_user_clicks[\"user_id\"].iloc[0]\n",
    "\n",
    "# Générer les recommandations\n",
    "recommendations = get_content_based_recommendations(\n",
    "    some_user_id,\n",
    "    df_user_clicks,\n",
    "    df_embeddings,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "print(\"✅ Recommandations Content-Based pour l'utilisateur\", some_user_id)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5da42d",
   "metadata": {},
   "source": [
    "J’ai implémenté les deux approches comme demandé. Pour la mise en production, j’ai choisi le Content-Based Filtering car il est plus léger, ne nécessite pas de modèle entraîné à charger, et reste très pertinent avec les bons embeddings. Cela me permet de respecter les contraintes d’un environnement cloud gratuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7be224",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
